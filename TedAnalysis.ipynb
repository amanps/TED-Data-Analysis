{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import ast\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "ted = pd.read_csv(\"ted_main.csv\")\n",
    "transcript = pd.read_csv('transcripts.csv')\n",
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted.head()\n",
    "ted.film_date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted[\"views\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted.boxplot(column = \"comments\")\n",
    "ted[\"comments\"].quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted.boxplot(column = \"views\")\n",
    "ted[\"views\"].quantile(0.9)\n",
    "ted[ted[\"views\"] > 3051912].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted.boxplot(column = \"duration\")\n",
    "# ted[\"duration\"].quantile(0.9)\n",
    "# ted[\"duration\"].max()\n",
    "ted[ted[\"duration\"] == 5256].title\n",
    "ted[ted[\"duration\"] == 5256].main_speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total count for each rating. Most talks pick up the inspiring rating.\n",
    "\n",
    "import operator\n",
    "ratings = {}\n",
    "for index, rating_str in ted[\"ratings\"].iteritems():\n",
    "    ratings_list = ast.literal_eval(rating_str)\n",
    "    for rating in ratings_list:\n",
    "        ratings[rating[\"name\"]] = ratings.get(rating[\"name\"], 0) + rating[\"count\"]\n",
    "for i in sorted(ratings.items(), key=operator.itemgetter(1))[::-1]:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding columns with counts for all ratings for a talk.\n",
    "\n",
    "ratings_df = ted.copy()\n",
    "ratings_list = ratings.keys()\n",
    "for rating in ratings_list:\n",
    "    ratings_df[rating] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Speakers with more than 1 talk.\n",
    "\n",
    "import operator\n",
    "name_dict = {}\n",
    "for name in ted[\"main_speaker\"].iteritems():\n",
    "    name_dict[name[1]] = name_dict.get(name[1], 0) + 1\n",
    "count = 0\n",
    "for k in sorted(name_dict.items(), key = operator.itemgetter(1)):\n",
    "    if k[1] > 1:\n",
    "        print (\"%s - %s\" % (k[0], k[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set of all tags\n",
    "\n",
    "tag_set = set()\n",
    "for tag_str in ted[\"tags\"]:\n",
    "    tag_list = ast.literal_eval(tag_str)\n",
    "    for tag in tag_list:\n",
    "        tag_set.add(tag)\n",
    "print(tag_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print tags per talk of speaker.\n",
    "\n",
    "def print_tags_for_speaker(speaker):\n",
    "    rosling = ted[ted[\"main_speaker\"] == speaker]\n",
    "    tag_set = []\n",
    "    for tag_str in rosling[\"tags\"]:\n",
    "        tag_list = ast.literal_eval(tag_str)\n",
    "        tag_set.append(tag_list)\n",
    "    print(tag_set)\n",
    "\n",
    "print_tags_for_speaker(\"Hans Rosling\")\n",
    "# print_tags_for_speaker(\"Juan Enriquez\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Most viewed talks.\n",
    "\n",
    "most_viewed = ted[[\"title\", \"main_speaker\", \"views\"]].sort_values(\"views\", ascending=False)\n",
    "most_viewed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Most commented on talks\n",
    "\n",
    "most_commented = ted[[\"title\", \"main_speaker\", \"views\", \"comments\"]].sort_values(\"comments\", ascending=False)\n",
    "most_commented.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# There doesn't seem to be any correlation between views and comments. The top viewed TED talk is not the top commented \n",
    "# inspite of having 10 times more views than the top commented one \"Militant Atheism\".\n",
    "\n",
    "display(ted.plot(x = \"views\", y = \"comments\", kind = \"scatter\"))\n",
    "display(ted[(ted[\"comments\"] < 400) & (ted[\"views\"] < 3050000)].plot(x = \"views\", y = \"comments\", kind = \"scatter\"))\n",
    "display(ted[(ted[\"views\"] < 500000) & (ted[\"comments\"] > 600)].head())\n",
    "display(ted[(ted[\"views\"] > 3000000) & (ted[\"comments\"] < 50)].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We observe that views and languages are slightly positively correlated 0.3, TED talks with more than 10 million \n",
    "# have atleast 28 languages\n",
    "\n",
    "ted.plot(x = \"views\", y = \"languages\", kind = \"scatter\")\n",
    "ted[ted[\"views\"] > 10000000].languages.sort_values().head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Each rating with the associated score for each talk normalized over the number of views. \n",
    "\n",
    "def populate_ratings():\n",
    "    for index, rating_str in ratings_df[\"ratings\"].iteritems():\n",
    "        max_rating = -1\n",
    "        ratings_list = ast.literal_eval(rating_str)\n",
    "        for rating in ratings_list:\n",
    "            ratings_df.loc[index, rating[\"name\"]] = rating[\"count\"] / ted.iloc[index][\"views\"]\n",
    "populate_ratings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_list = [\"title\", \"main_speaker\"] + list(ratings_list)\n",
    "ratings_df[display_list].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rating in ratings_list:\n",
    "    display(ratings_df.sort_values(by = rating, ascending = False)[[\"title\", rating, \"views\"]].head(5))\n",
    "    \n",
    "# This gives us a more accurate description of whether the talk was funny/inspiring etc. This is per user how many \n",
    "# people found it funny as opposed to overall coz it may be biased for a talk with more views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ratings_df[list(ratings_list)].corr()\n",
    "# display(ratings_df[[\"Jaw-dropping\", \"Unconvincing\", \"Fascinating\", \"Confusing\", \"OK\", \"Longwinded\", \"Beautiful\"]].corr())\n",
    "# display(ratings_df[[\"Persuasive\", \"Unconvincing\", \"Informative\", \"Confusing\", \"OK\", \"Funny\"]].corr())\n",
    "positive = ratings_df[[\"Jaw-dropping\", \"Unconvincing\", \"Fascinating\", \"Confusing\", \"OK\", \"Longwinded\", \"Beautiful\"]]\n",
    "negative = ratings_df[[\"Persuasive\", \"Unconvincing\", \"Informative\", \"Confusing\", \"OK\", \"Funny\"]]\n",
    "display(scatter_matrix(positive, alpha=1, figsize=(14, 14), diagonal='kde'))\n",
    "display(scatter_matrix(negative, alpha=1, figsize=(14, 14), diagonal='kde'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from pandas.plotting import scatter_matrix\n",
    "# display(scatter_matrix(ratings_df[list(ratings_list)], alpha=0.2, figsize=(14, 14), diagonal='kde'))\n",
    "\n",
    "# We were expecting positive correlation between some ratings which we were able to verify. \n",
    "# Didn't seem to find any negative correlation which was surprising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dtm(lst):\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'[a-zA-Z]+') #Only english alphabets\n",
    "    res = []\n",
    "    for script in lst:\n",
    "        d = {}\n",
    "        d['audience_laughter'] = script.lower().count('(laughter)')\n",
    "        d['audience_applause'] = script.lower().count('(applause)')\n",
    "        tokens =  tokenizer.tokenize(script.lower())\n",
    "        for word in tokens:\n",
    "            if word in stopWords:\n",
    "                continue\n",
    "            d[word] =  d.get(word,0) + 1\n",
    "        res.append(d)\n",
    "    return pd.DataFrame(res).fillna(0)\n",
    "\n",
    "#Creating the document term matrix\n",
    "dtm = make_dtm(transcript.transcript)\n",
    "print(dtm.shape)\n",
    "dtm_end = dtm.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcount(script):\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'[a-zA-Z]+') #Only english alphabets\n",
    "    tokens =  tokenizer.tokenize(script.lower())\n",
    "    return len(tokens)\n",
    "\n",
    "#Features to calculate word per minutes\n",
    "ted['duration_min'] = round(ted.duration / 60)\n",
    "transcript['words'] = transcript['transcript'].apply(wordcount)\n",
    "dtm['word_count'] = transcript.words\n",
    "dtm['url_match'] = transcript.url\n",
    "\n",
    "#Creating the combined dataframe\n",
    "full_df = pd.merge(dtm,ratings_df, left_on = 'url_match', right_on = 'url')\n",
    "full_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word per minute calculations\n",
    "full_df['wpm'] = full_df['word_count'] / full_df['duration_min']\n",
    "full_df['wpm_category'] = ['Optimal' if (i >= 140 and i <= 160) else 'Fast' if i > 160 else 'Slow' for i in full_df.wpm]\n",
    "print(full_df.wpm.describe())\n",
    "print(full_df.wpm_category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top occuring words excluding stop words\n",
    "dtm.iloc[:,:dtm_end].sum().sort_values(ascending = False)[:20].plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(max_font_size=40).generate(' '.join(transcript.transcript))\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word per minute analysis\n",
    "agg_list = {}\n",
    "for rating in ratings_list:\n",
    "    agg_list[rating] = 'mean'\n",
    "\n",
    "full_df.groupby(['wpm_category']).agg(agg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "ted[\"year\"] = -1\n",
    "def populate_years():\n",
    "    for index, epoch in ted[\"published_date\"].iteritems():\n",
    "        ted.loc[index, \"year\"] = datetime.fromtimestamp(epoch).year\n",
    "\n",
    "populate_years()\n",
    "ted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ted.year.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_dict_list = []\n",
    "\n",
    "for year in ted.year.unique():\n",
    "    tag_dict = {}\n",
    "    for index, talk in ted[ted[\"year\"] == year].iterrows():\n",
    "        tags_list = ast.literal_eval(talk[\"tags\"])\n",
    "        for tag in tags_list:\n",
    "            tag_dict[tag] = tag_dict.get(tag, 0) + 1\n",
    "    tag_dict_list.append(tag_dict)\n",
    "\n",
    "year_tag_df = pd.DataFrame(tag_dict_list).fillna(0)\n",
    "year_tag_df = year_tag_df.set_index(ted.year.unique())\n",
    "year_tag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 tags of 2016-17\n",
    "year_tag_df.loc[[2016,2017],:].sum().sort_values(ascending = False)[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
